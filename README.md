# Projeto MLOps: An√°lise de Sentimento End-to-End

Este projeto implementa um sistema completo de MLOps para um modelo de an√°lise de sentimento. Ele abrange desde o processamento inicial de dados e treinamento at√© o deploy de uma API de infer√™ncia, monitoramento cont√≠nuo e retreinamento automatizado.

## üìú Vis√£o Geral da Arquitetura

O sistema √© orquestrado em cont√™ineres Docker e utiliza uma arquitetura de microsservi√ßos para garantir desacoplamento e escalabilidade.

```
      +-----------------+      +-----------------+      +-----------------+
      |  Frontend (UI)  |----->|   API (FastAPI) |----->|  MLflow Server  |
      |   (Streamlit)   |      +-----------------+      | (Model Registry)|
      +-----------------+               |               +-------+---------+
                                        |                       |
      +-----------------+               |                       |
      | Dashboard (UI)  |<--------------+-----------------------+------>+------------------+
      |   (Streamlit)   |               |                               |  App Database    |
      +-----------------+               |                               | (Postgres - App) |
                                        |                               | - Features       |
      +-----------------+               v                               | - Prediction Logs|
      | Airflow         |<------------>+------------------+              | - MLflow Backend |
      | - Webserver     |                                               +------------------+
      | - Scheduler     |
      | - Worker(s)     |
      +-----------------+
```

### Componentes Principais

*   **Airflow**: Orquestra os pipelines de dados e machine learning.
    *   **ETL Inicial**: Um pipeline para processar o dataset bruto, extrair features e treinar a primeira vers√£o do modelo.
    *   **Ciclo de Vida do Modelo**: Uma DAG di√°ria que monitora a performance do modelo em produ√ß√£o, detecta data drift, verifica novos feedbacks e dispara o retreinamento quando necess√°rio.
*   **MLflow**: Centraliza o ciclo de vida do modelo.
    *   **Tracking**: Registra experimentos, par√¢metros, m√©tricas e artefatos de cada treinamento.
    *   **Model Registry**: Versiona os modelos e gerencia seus est√°gios (Staging, Production).
*   **FastAPI**: Fornece uma API RESTful para servir as predi√ß√µes do modelo em produ√ß√£o.
*   **PostgreSQL (x2)**:
    *   **`postgres`**: Banco de dados de metadados exclusivo para o Airflow.
    *   **`postgres_app` (ali√°s `postgres_bacen`)**: Banco de dados da aplica√ß√£o, que armazena:
        *   `reviews_features`: Uma "Feature Store" simplificada com os dados processados para treinamento.
        *   `logs_predicoes`: Logs de todas as predi√ß√µes feitas pela API, incluindo feedbacks.
        *   *MLflow Backend*: Tabelas para armazenar os metadados de experimentos e modelos do MLflow.
*   **Streamlit (x2)**:
    *   **Frontend**: Uma interface de usu√°rio simples para interagir com a API de predi√ß√£o.
    *   **Dashboard**: Um painel para monitorar a sa√∫de do modelo, visualizar m√©tricas e predi√ß√µes de baixa confian√ßa.
*   **Celery & Redis**: Utilizados pelo Airflow para executar tarefas de forma distribu√≠da e ass√≠ncrona.

## üöÄ Setup e Instala√ß√£o

### Pr√©-requisitos
*   Docker
*   Docker Compose

### Passos para Instala√ß√£o

1.  **Clone o Reposit√≥rio**
    ```bash
    git clone <url-do-seu-repositorio>
    cd ML_projeto_final
    ```

2.  **Crie o Arquivo de Ambiente**
    Copie o arquivo de exemplo `.env.example` para `.env`.
    ```bash
    cp .env.example .env
    ```
    Abra o arquivo `.env` e gere uma chave Fernet para o Airflow:
    ```bash
    # No seu terminal, execute o comando abaixo e copie o resultado
    python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
    ```
    Cole a chave gerada na vari√°vel `AIRFLOW_FERNET_KEY` dentro do arquivo `.env`.

    Seu arquivo .env deve conter as seguintes vari√°veis (ajuste conforme necess√°rio):
    ```bash
    POSTGRES_USER=airflow
    POSTGRES_PASSWORD=airflow123
    POSTGRES_DB_APP=bacen
    MLFLOW_DB_USER=airflow
    MLFLOW_DB_PASSWORD=airflow123
    MLFLOW_DB_NAME=mlflow_db
    AIRFLOW_FERNET_KEY=<cole_a_chave_gerada_aqui>
    AIRFLOW_UID=50000
    ```

3.  **Defina o ID do Usu√°rio Airflow**
    Para evitar problemas de permiss√£o com os arquivos gerados pelo Airflow, defina o ID do seu usu√°rio local.
    ```bash
    echo "AIRFLOW_UID=$(id -u)" >> .env
    ```

4.  **Inicie os Servi√ßos**
    Execute o Docker Compose para construir as imagens e iniciar todos os cont√™ineres em segundo plano.
    ```bash
    docker-compose up -d --build
    ```
    A primeira inicializa√ß√£o pode levar alguns minutos, pois o Airflow precisa inicializar seu banco de dados.

## ‚öôÔ∏è Como Operar o Sistema

### Passo 1: Treinamento Inicial

O sistema come√ßa sem nenhum modelo treinado. Voc√™ precisa executar o pipeline de ETL e treinamento inicial manualmente.

1.  Acesse a interface do Airflow: `http://localhost:8080` (usu√°rio/senha: `airflow`/`airflow`).
2.  Encontre a DAG `sentiment_initial_etl_and_training`.
3.  Ative a DAG clicando no bot√£o de toggle e, em seguida, clique no bot√£o "Play" (‚ñ∂Ô∏è) para disparar uma execu√ß√£o.

Este processo ir√°:
*   Ler o dataset da Olist.
*   Processar e salvar as features no banco de dados da aplica√ß√£o (tabela reviews_features).
*   Treinar m√∫ltiplos modelos de classifica√ß√£o (Logistic Regression / Random Forest / XGBoost / LinearSVC_Calibrated / LightGBM), selecionar o melhor, valid√°-lo e promov√™-lo para "Production" no MLflow.

### Passo 2: Utilizando a API

Ap√≥s o primeiro modelo ser treinado e promovido, a API estar√° pronta para servir predi√ß√µes.

*   **Documenta√ß√£o Interativa (Swagger)**: `http://localhost:8000/docs`
*   **Exemplo de Requisi√ß√£o `POST /predict`**:
    ```bash
    curl -X 'POST' \
      'http://localhost:8000/predict' \
      -H 'Content-Type: application/json' \
      -d '{
      "message": "Consegui resolver o meu problema no chat. Atendimento super √°gil!"
    }'
    ```

### Passo 3: Fornecendo Feedback

Cada predi√ß√£o retorna um `prediction_id`. Use este ID para registrar um feedback, que ser√° usado no retreinamento.

*   **Exemplo de Requisi√ß√£o `POST /feedback/{prediction_id}`**:
    ```bash
    curl -X 'POST' \
      'http://localhost:8000/feedback/1?feedback=INCORRETO&corrected_class=INSATISFEITO'
    ```

### Passo 4: Ciclo de Vida Automatizado

A DAG `sentiment_model_lifecycle` √© executada automaticamente todos os dias. Ela:
1.  Verifica se a distribui√ß√£o das predi√ß√µes recentes mudou (data drift).
2.  Verifica se h√° um n√∫mero suficiente de novos feedbacks (padr√£o: 50).
3.  Se qualquer uma das condi√ß√µes for atendida, ela dispara o pipeline de retreinamento.
4.  O novo modelo treinado √© comparado com o modelo em produ√ß√£o (padr√£o Champion-Challenger).
5.  Se o novo modelo for melhor, ele √© automaticamente promovido para "Production", e a API passar√° a us√°-lo na pr√≥xima reinicializa√ß√£o ou na pr√≥xima carga.

## üåê Acessando os Servi√ßos

*   **Airflow UI**: `http://localhost:8080`
*   **Flower (Monitoramento Celery)**: `http://localhost:5555`
*   **MLflow UI**: `http://localhost:5000`
*   **API (Swagger UI)**: `http://localhost:8000/docs`
*   **Frontend App**: `http://localhost:8501`
*   **Dashboard de Monitoramento**: `http://localhost:8601`
*   **pgAdmin (Admin do Banco)**: `http://localhost:5050`

## üìÇ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ dags/                 # Defini√ß√µes das DAGs do Airflow
‚îú‚îÄ‚îÄ data/                 # Datasets brutos
‚îú‚îÄ‚îÄ docker/               # Dockerfiles para cada servi√ßo
‚îú‚îÄ‚îÄ logs/                 # Logs do Airflow (mapeado do cont√™iner)
‚îú‚îÄ‚îÄ mlflow_artifacts/     # Artefatos do MLflow (modelos, etc.)
‚îú‚îÄ‚îÄ src/                  # C√≥digo-fonte da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ api/              # L√≥gica da API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ db/               # Defini√ß√µes de schema e reposit√≥rio do banco
‚îÇ   ‚îú‚îÄ‚îÄ etl/              # Scripts para os pipelines de ETL e retreino
‚îÇ   ‚îú‚îÄ‚îÄ frontend/         # C√≥digo do app Streamlit de intera√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ models/           # L√≥gica de treinamento e avalia√ß√£o de modelos
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/       # L√≥gica para o dashboard e detec√ß√£o de drift
‚îú‚îÄ‚îÄ .env                  # Vari√°veis de ambiente (secretas)
‚îú‚îÄ‚îÄ .env.example          # Arquivo de exemplo para o .env
‚îú‚îÄ‚îÄ docker-compose.yaml   # Orquestra√ß√£o de todos os servi√ßos
‚îî‚îÄ‚îÄ README.md             # Esta documenta√ß√£o
```

## Rodando testes
```bash
pytest
```
Para rodar os testes de unidade do projeto, execute o comando a seguir na raiz do reposit√≥rio:
```bash
pytest -q
```