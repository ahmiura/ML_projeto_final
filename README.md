# Pipeline de MLOps: An√°lise de Sentimento de E-commerce

Este projeto implementa uma plataforma completa de **MLOps (Machine Learning Operations)** para an√°lise de sentimento de avalia√ß√µes de clientes.

A solu√ß√£o utiliza uma arquitetura de microservi√ßos para garantir escalabilidade, reprodutibilidade e monitoramento cont√≠nuo do ciclo de vida do modelo de Machine Learning.

## üèõÔ∏è Arquitetura do Projeto

O sistema foi desenhado seguindo o padr√£o de **Monorepo Modular**, onde o c√≥digo de neg√≥cio √© compartilhado entre os servi√ßos de treinamento e infer√™ncia para evitar discrep√¢ncia de dados (*Training-Serving Skew*).

### Componentes Principais (Docker Containers)

1.  **Airflow (Orquestrador):** Gerencia o pipeline de dados (ETL) e o retreinamento peri√≥dico dos modelos.
    * *Executor:* Celery (Distribu√≠do) com Redis.
2.  **PostgreSQL (Feature Store & Metadados):**
    * Armazena os dados tratados (`reviews_features`) prontos para treinamento.
    * Serve como backend para o Airflow e MLflow.
3.  **MLflow (Model Registry):**
    * Rastreia experimentos (m√©tricas, par√¢metros).
    * Gerencia o versionamento dos modelos e promove o melhor (F1-score) para "Produ√ß√£o".
4.  **API (Serving):**
    * Servi√ßo FastAPI.
    * Carrega automaticamente a vers√£o de produ√ß√£o do modelo do MLflow.
5.  **Frontend:**
    * Aplica√ß√£o Streamlit para intera√ß√£o com o usu√°rio e teste do modelo em tempo real.

---

## üöÄ Como Executar o Projeto

### Pr√©-requisitos
* Docker e Docker Compose instalados.
* Git.

### Passo a Passo

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/ml_projeto_final.git](https://github.com/seu-usuario/ml_projeto_final.git)
    cd ml_projeto_final
    ```

2.  **Configure as Credenciais:**
    Crie um arquivo `.env` na raiz do projeto (baseado no exemplo abaixo) para definir as senhas do banco de dados e chaves de seguran√ßa.

    ```env
    POSTGRES_USER=airflow
    POSTGRES_PASSWORD=airflow123
    POSTGRES_DB_APP=bacen
    
    MLFLOW_DB_USER=airflow
    MLFLOW_DB_PASSWORD=airflow123
    MLFLOW_DB_NAME=mlflow_db
    
    # Gere uma chave Fernet v√°lida para o Airflow
    AIRFLOW_FERNET_KEY=SuaChaveGeradaAqui...
    AIRFLOW_UID=50000
    ```

3.  **Construa e Inicie os Servi√ßos:**
    ```bash
    # 1. Construir as imagens Docker (pode levar alguns minutos)
    docker-compose build

    # 2. Inicializar o banco de dados do Airflow
    docker-compose up airflow-init

    # 3. Subir todo o ambiente em background
    docker-compose up -d
    ```

4.  **Acesse os Servi√ßos:**

    | Servi√ßo | URL | Credenciais (Padr√£o) |
    | :--- | :--- | :--- |
    | **Airflow** | [http://localhost:8080](http://localhost:8080) | `airflow` / `airflow` |
    | **MLflow** | [http://localhost:5000](http://localhost:5000) | - |
    | **API Docs** | [http://localhost:8000/docs](http://localhost:8000/docs) | - |
    | **Frontend** | [http://localhost:8501](http://localhost:8501) | - |
    | **PgAdmin** | [http://localhost:5050](http://localhost:5050) | `admin@admin.com` / `admin` |

---

## üß™ Executando o Pipeline

1.  Acesse o **Airflow** (`localhost:8080`).
2.  Ative o DAG **`olist_sentiment_pipeline`**.
3.  O pipeline executar√° automaticamente as etapas:
    * **Extra√ß√£o:** L√™ o dataset bruto (`data/olist_order_reviews_dataset.csv`).
    * **Transforma√ß√£o:** Limpa o texto e cria features.
    * **Carga:** Salva os dados processados no PostgreSQL.
    * **Treinamento:** Treina m√∫ltiplos modelos (Logistic Regression, Random Forest, XGBoost), compara a performance e registra o vencedor no MLflow.

## üìä Monitoramento e Melhoria Cont√≠nua

* **MLflow:** Acesse para ver o hist√≥rico de treinamentos, comparar a acur√°cia dos modelos e ver qual algoritmo venceu a batalha.
* **API:** Reinicie a API (`docker-compose restart api`) ap√≥s um novo treinamento para que ela carregue automaticamente a nova vers√£o do modelo campe√£o promovido a produ√ß√£o.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.9+
* **Machine Learning:** Scikit-Learn, XGBoost
* **Engenharia de Dados:** Pandas, SQLAlchemy
* **Infraestrutura:** Docker, Docker Compose, Redis
* **MLOps:** Apache Airflow, MLflow
* **Web:** FastAPI, Streamlit

---